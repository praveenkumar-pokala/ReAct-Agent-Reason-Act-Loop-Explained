{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Naive one-shot LLM vs ReAct with tools \u2014 comparison"]}, {"cell_type": "code", "metadata": {}, "source": ["import os, textwrap\n", "from openai import OpenAI\n", "\n", "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n", "MODEL_NAME = \"gpt-4o-mini\"\n", "\n", "user_query = (\n", "    \"I am traveling to Bangalore for a 3-day business trip near the main tech park. \"\n", "    \"Recommend a good business hotel and tell me what to pack based on the current weather. \"\n", "    \"I prefer not to spend more than 5500 INR per night.\"\n", ")\n", "print(\"Using model:\", MODEL_NAME)\n", "print(\"User query:\\n\", user_query)"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Naive one-shot answer"]}, {"cell_type": "code", "metadata": {}, "source": ["def naive_llm_answer(query: str) -> str:\n", "    resp = client.chat.completions.create(\n", "        model=MODEL_NAME,\n", "        messages=[\n", "            {\"role\": \"system\", \"content\": \"You are a helpful travel assistant.\"},\n", "            {\"role\": \"user\", \"content\": query},\n", "        ],\n", "        temperature=0.7,\n", "    )\n", "    return resp.choices[0].message.content\n", "\n", "naive_answer = naive_llm_answer(user_query)\n", "print(\"Naive LLM answer:\\n\")\n", "print(naive_answer)"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. ReAct agent answer (reusing simplified logic)"]}, {"cell_type": "code", "metadata": {}, "source": ["from dataclasses import dataclass\n", "from typing import List, Dict, Callable, Optional\n", "import requests\n", "\n", "@dataclass\n", "class ToolResult:\n", "    name: str\n", "    input: str\n", "    output: str\n", "\n", "def hotel_search_bangalore(query: str) -> str:\n", "    hotels = [\n", "        {\n", "            \"name\": \"Orion Business Hotel\",\n", "            \"area\": \"Whitefield\",\n", "            \"distance_km_to_office\": 1.2,\n", "            \"price_band_inr\": \"4500-5500\",\n", "            \"notes\": \"Walkable to tech park, good Wi-Fi, quiet, popular with business travelers.\"\n", "        },\n", "        {\n", "            \"name\": \"Skyline Executive Suites\",\n", "            \"area\": \"Indiranagar\",\n", "            \"distance_km_to_office\": 8.0,\n", "            \"price_band_inr\": \"5000-6500\",\n", "            \"notes\": \"Great restaurants nearby, slightly longer commute in traffic.\"\n", "        },\n", "        {\n", "            \"name\": \"Airport Link Business Hotel\",\n", "            \"area\": \"Near Airport\",\n", "            \"distance_km_to_office\": 30.0,\n", "            \"price_band_inr\": \"4000-5200\",\n", "            \"notes\": \"Good for late-night arrivals, but long commute to office area.\"\n", "        },\n", "    ]\n", "    lines = [\"Bangalore business hotels (internal catalog):\", \"\"]\n", "    for h in hotels:\n", "        lines.append(\n", "            f\"- {h['name']} ({h['area']}): \"\n", "            f\"{h['distance_km_to_office']}km to office, \"\n", "            f\"{h['price_band_inr']} INR/night. Notes: {h['notes']}\"\n", "        )\n", "    lines.append(\"\")\n", "    lines.append(\"Choose one that balances commute time and comfort based on traveler role and arrival time.\")\n", "    return \"\\n\".join(lines)\n", "\n", "def weather_snapshot(city: str) -> str:\n", "    try:\n", "        if city.lower().startswith(\"bangalore\") or city.lower().startswith(\"bengaluru\"):\n", "            lat, lon = 12.9716, 77.5946\n", "        else:\n", "            lat, lon = 12.9716, 77.5946\n", "        resp = requests.get(\n", "            \"https://api.open-meteo.com/v1/forecast\",\n", "            params={\"latitude\": lat, \"longitude\": lon, \"current_weather\": True},\n", "            timeout=10,\n", "        )\n", "        if resp.status_code != 200:\n", "            return f\"[weather] API error {resp.status_code}: {resp.text[:200]}\"\n", "        data = resp.json()\n", "        cw = data.get(\"current_weather\", {})\n", "        temp_c = cw.get(\"temperature\")\n", "        wind = cw.get(\"windspeed\")\n", "        cond_code = cw.get(\"weathercode\")\n", "        return (\n", "            f\"Current weather for {city}: {temp_c}\u00b0C, wind {wind} km/h, \"\n", "            f\"weathercode {cond_code} (see open-meteo codes). \"\n", "            f\"Evenings can feel cooler; pack a light jacket.\"\n", "        )\n", "    except Exception as e:\n", "        return f\"[weather] fallback: could not retrieve live data ({e}). Assume warm but variable; pack breathable clothes and a light jacket.\"\n", "\n", "TOOLS: Dict[str, Callable[[str], str]] = {\n", "    \"hotel_search_bangalore\": hotel_search_bangalore,\n", "    \"weather_snapshot\": weather_snapshot,\n", "}\n", "\n", "TOOL_DESCRIPTIONS = \"\"\"\n", "You have access to the following tools:\n", "\n", "1. hotel_search_bangalore(query: str)\n", "2. weather_snapshot(city: str)\n", "\"\"\"\n", "\n", "SYSTEM_PROMPT = f\"\"\"\n", "You are a ReAct-style travel agent. Follow this format:\n", "\n", "Thought: <your reasoning>\n", "Action: <hotel_search_bangalore or weather_snapshot>\n", "Action Input: <a single-line argument>\n", "\n", "... repeat Thought -> Action -> Observation as needed ...\n", "\n", "When done, respond with:\n", "Final Answer: <your complete answer>\n", "\"\"\"\n", "\n", "def call_llm(messages: List[Dict[str, str]]) -> str:\n", "    resp = client.chat.completions.create(\n", "        model=MODEL_NAME,\n", "        messages=messages,\n", "        temperature=0.3,\n", "    )\n", "    return resp.choices[0].message.content\n", "\n", "def parse_react_step(text: str):\n", "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n", "    for line in lines:\n", "        if line.startswith(\"Final Answer:\"):\n", "            return {\"type\": \"final\", \"answer\": line[len(\"Final Answer:\"):].strip()}\n", "    tool = None\n", "    tool_input = None\n", "    for line in lines:\n", "        if line.startswith(\"Action:\"):\n", "            tool = line[len(\"Action:\"):].strip()\n", "        elif line.startswith(\"Action Input:\"):\n", "            tool_input = line[len(\"Action Input:\"):].strip().strip('\"')\n", "    if tool and tool_input is not None:\n", "        return {\"type\": \"action\", \"tool\": tool, \"tool_input\": tool_input}\n", "    return {\"type\": \"unknown\", \"raw\": text}\n", "\n", "def run_react_agent(query: str, max_steps: int = 6):\n", "    messages = [\n", "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT + \"\\n\" + TOOL_DESCRIPTIONS},\n", "        {\"role\": \"user\", \"content\": query},\n", "    ]\n", "    trace: List[ToolResult] = []\n", "    final_answer = None\n", "    for step in range(1, max_steps + 1):\n", "        print(f\"\\n=== ReAct Step {step} ===\")\n", "        out = call_llm(messages)\n", "        print(\"LLM raw output:\\n\", out)\n", "        parsed = parse_react_step(out)\n", "        if parsed[\"type\"] == \"final\":\n", "            final_answer = parsed[\"answer\"]\n", "            print(\"[ReAct agent produced Final Answer]\")\n", "            break\n", "        if parsed[\"type\"] == \"action\":\n", "            tool_name = parsed[\"tool\"]\n", "            tool_input = parsed[\"tool_input\"]\n", "            if tool_name in TOOLS:\n", "                obs = TOOLS[tool_name](tool_input)\n", "            else:\n", "                obs = f\"[error] unknown tool: {tool_name}\"\n", "            trace.append(ToolResult(name=tool_name, input=tool_input, output=obs))\n", "            messages.append({\"role\": \"assistant\", \"content\": out})\n", "            messages.append({\"role\": \"user\", \"content\": f\"Observation: {obs}\"})\n", "            continue\n", "        messages.append({\"role\": \"assistant\", \"content\": out})\n", "    return {\"trace\": trace, \"final_answer\": final_answer}\n", "\n", "react_result = run_react_agent(user_query, max_steps=6)\n", "print(\"\\nReAct FINAL ANSWER:\\n\", react_result[\"final_answer\"])"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Side-by-side comparison"]}, {"cell_type": "code", "metadata": {}, "source": ["print(\"===== Naive one-shot answer =====\\n\")\n", "print(textwrap.indent(naive_answer, prefix=\"  \"))\n", "\n", "print(\"\\n\\n===== ReAct tool-grounded answer =====\\n\")\n", "print(textwrap.indent(react_result[\"final_answer\"], prefix=\"  \"))"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Inspect ReAct tool calls"]}, {"cell_type": "code", "metadata": {}, "source": ["for i, tr in enumerate(react_result[\"trace\"], start=1):\n", "    print(f\"\\n---------- ReAct Tool Call {i} ----------\")\n", "    print(f\"Tool: {tr.name}\")\n", "    print(f\"Input: {tr.input}\")\n", "    print(\"Output:\")\n", "    print(textwrap.indent(tr.output, prefix=\"  \"))"], "outputs": [], "execution_count": null}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}