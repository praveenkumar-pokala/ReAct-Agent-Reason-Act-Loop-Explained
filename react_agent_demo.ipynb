{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aecadec",
   "metadata": {},
   "source": [
    "# ReAct Agent: Reason + Act Loop Explained (Demo Notebook)\n",
    "\n",
    "This notebook is built to **teach** how a ReAct-style agent works using the structure from `ReAct-Agent-from-Scratch` (tools, prompts, loop with Thought → Action → Observation) citeturn1view0.\n",
    "\n",
    "We will do 5 things:\n",
    "1. Understand why ReAct exists (what problem it solves)\n",
    "2. Understand the loop: **Thought → Action → Observation → repeat**\n",
    "3. Map that loop to code structure in the repo (agent + tools + prompts + UI) citeturn1view0\n",
    "4. Run a tiny local demo loop\n",
    "5. Show how to extend the agent with your own tool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f1566",
   "metadata": {},
   "source": [
    "## 0. Why do we even need ReAct?\n",
    "\n",
    "LLMs are good at *thinking in text*, but bad at:\n",
    "- doing math reliably\n",
    "- searching the web live\n",
    "- fetching \"today's weather in Hyderabad\"\n",
    "- looking up factual data from Wikipedia\n",
    "\n",
    "ReAct fixes this by letting the model **think, then call tools** in a deliberate loop.\n",
    "\n",
    "The agent does:\n",
    "1. `Thought:` \"I should look up the weather in Hyderabad.\"\n",
    "2. `Action:` call `weather_tool(city=\"Hyderabad\")`\n",
    "3. `Observation:` tool returns \"30°C, mostly cloudy\"\n",
    "4. `Thought:` \"Now I can answer the user with accurate info.\"\n",
    "\n",
    "This means:\n",
    "- the model is not guessing\n",
    "- it is planning\n",
    "- it is verifying with real tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14e211",
   "metadata": {},
   "source": [
    "## 1. High-level loop\n",
    "\n",
    "The standard ReAct loop looks like this (simplified):\n",
    "\n",
    "```text\n",
    "User Question\n",
    "↓\n",
    "LLM produces:\n",
    "  Thought: what do I need?\n",
    "  Action: which tool should I call and with what arguments?\n",
    "PAUSE\n",
    "Tool is executed in Python\n",
    "↓\n",
    "We capture:\n",
    "  Observation: tool result\n",
    "↓\n",
    "LLM is called again with the full transcript so far\n",
    "  (Thought, Action, Observation history)\n",
    "↓\n",
    "Either:\n",
    "  - pick another tool\n",
    "  - OR produce final answer for the user\n",
    "```\n",
    "\n",
    "So the agent is literally *thinking, acting, reading the result, thinking again*.\n",
    "That's why it's called **ReAct**: **Re**ason + **Act**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e46dbf0",
   "metadata": {},
   "source": [
    "## 2. Repository mental model\n",
    "\n",
    "In `ReAct-Agent-from-Scratch`, the repo is organized something like this (based on the GitHub listing) citeturn1view0:\n",
    "\n",
    "```text\n",
    "ReAct-Agent-from-Scratch/\n",
    "    agent.py          <- the main agent loop (ReAct core logic)\n",
    "    prompts/          <- system prompts / instruction templates\n",
    "    tools/            <- python tools: calculator, web search, weather, wikipedia\n",
    "    utils/            <- helpers (parsing, formatting, etc.)\n",
    "    web_app.py        <- Streamlit UI for interactive demo\n",
    "    test_queries.txt  <- example queries\n",
    "    requirements.txt  <- deps: streamlit, requests, openai/llm client, etc.\n",
    "```\n",
    "\n",
    "Conceptually:\n",
    "- `agent.py` = the brain\n",
    "- `tools/` = hands + senses\n",
    "- `web_app.py` = face / UI\n",
    "\n",
    "You can teach this analogy in leadership talks. It lands.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad5b06",
   "metadata": {},
   "source": [
    "## 3. Let's build a *mini* ReAct Agent locally in this notebook\n",
    "\n",
    "We'll implement:\n",
    "- A **Tool Registry** (a dict of callable tools)\n",
    "- A tiny **LLM policy stub** (pretend LLM that decides which tool to call)\n",
    "- A **ReAct loop runner**\n",
    "\n",
    "In your actual repo, the model would be OpenAI / DeepSeek / Gemini etc., and it would generate Thought / Action text.  Here we will simulate that behavior in a controlled way so it's 100% offline and reproducible for teaching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfcea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Callable, Any, Tuple\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Tools\n",
    "# -----------------------------\n",
    "\n",
    "def tool_calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Very dumb calculator for demo.\n",
    "    Supports +, -, *, / between two numbers.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}})\n",
    "        return f\"{result}\"\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\"\n",
    "\n",
    "def tool_wikipedia_stub(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Offline fake wikipedia tool.\n",
    "    In the real repo, this would call Wikipedia and retrieve summary text.\n",
    "    \"\"\"\n",
    "    db = {\n",
    "        \"hyderabad\": \"Hyderabad is a major tech hub in India, known for HITEC City and rich food culture.\",\n",
    "        \"react agent\": \"ReAct is a prompting / agent pattern combining reasoning steps and tool usage.\"\n",
    "    }\n",
    "    return db.get(query.lower(), \"No offline summary found.\")\n",
    "\n",
    "# Tool registry – like tools/ folder in repo\n",
    "TOOLS: Dict[str, Callable[..., str]] = {\n",
    "    \"calculator\": tool_calculator,\n",
    "    \"wikipedia\": tool_wikipedia_stub,\n",
    "}\n",
    "TOOLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0968686",
   "metadata": {},
   "source": [
    "### 3.1 The 'LLM policy'\n",
    "In the real repo, the agent asks the LLM:\n",
    "- Given conversation so far,\n",
    "- Should I answer now,\n",
    "- or should I call a tool? Which one? With what input?\n",
    "\n",
    "The LLM responds in a standardized format like:\n",
    "\n",
    "```text\n",
    "Thought: I should look up X\n",
    "Action: wikipedia\n",
    "Action Input: \"Hyderabad\"\n",
    "```\n",
    "\n",
    "Here in the notebook, we'll *fake* the model policy using handwritten rules.  \n",
    "This keeps the logic transparent for students.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe97007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_policy(user_message: str, scratchpad: str) -> Tuple[str, str, str]:\n",
    "    \"\"\"\n",
    "    This simulates what the LLM would output.\n",
    "    Returns (thought, action_name, action_input).\n",
    "\n",
    "    Rules for demo:\n",
    "    - if user asks arithmetic -> call calculator\n",
    "    - if user asks 'who/what is ...' -> call wikipedia\n",
    "    - else -> answer directly (no tool)\n",
    "    \"\"\"\n",
    "    lower_msg = user_message.lower()\n",
    "\n",
    "    if any(op in lower_msg for op in [\"+\", \"-\", \"*\", \"/\"]):\n",
    "        return (\n",
    "            \"I should evaluate this math expression using calculator.\",\n",
    "            \"calculator\",\n",
    "            user_message,\n",
    "        )\n",
    "    if any(x in lower_msg for x in [\"who is\", \"what is\", \"tell me about\"]):\n",
    "        topic = (\n",
    "            lower_msg\n",
    "            .replace(\"who is\", \"\")\n",
    "            .replace(\"what is\", \"\")\n",
    "            .replace(\"tell me about\", \"\")\n",
    "            .strip(\" ?\")\n",
    "        )\n",
    "        return (\n",
    "            f\"I should look up {topic} on wikipedia.\",\n",
    "            \"wikipedia\",\n",
    "            topic,\n",
    "        )\n",
    "    return (\n",
    "        \"I can answer directly without using a tool.\",\n",
    "        \"final\",\n",
    "        user_message,\n",
    "    )\n",
    "\n",
    "simple_policy(\"What is Hyderabad?\", scratchpad=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c3588b",
   "metadata": {},
   "source": [
    "### 3.2 The ReAct loop runner\n",
    "\n",
    "This is the heart.  \n",
    "It does exactly what `agent.py` does in ReAct-Agent-from-Scratch style repos:\n",
    "1. Show the current transcript (chat history, thoughts, observations)\n",
    "2. Ask policy (LLM) what to do next\n",
    "3. If policy says \"final\", we return answer\n",
    "4. Else we execute the tool, record `Observation`, and continue\n",
    "\n",
    "We will also build a human-readable trace so you can show students EXACTLY how the agent is thinking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b626e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def react_loop(user_message: str, max_steps: int = 3) -> Dict[str, Any]:\n",
    "    transcript = []  # list of dicts: {role, content}\n",
    "    reasoning_trace = \"\"  # what we'll feed back to policy in real life\n",
    "    final_answer = None\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        thought, action_name, action_input = simple_policy(user_message, reasoning_trace)\n",
    "\n",
    "        reasoning_trace += f\"Thought: {thought}\\n\"\n",
    "\n",
    "        if action_name == \"final\":\n",
    "            final_answer = f\"Answer: {action_input}\"\n",
    "            reasoning_trace += final_answer + \"\\n\"\n",
    "            break\n",
    "\n",
    "        tool_fn = TOOLS.get(action_name)\n",
    "        if tool_fn is None:\n",
    "            observation = f\"ERROR: tool {action_name} not found\"\n",
    "        else:\n",
    "            observation = tool_fn(action_input)\n",
    "\n",
    "        reasoning_trace += f\"Action: {action_name}({action_input})\\n\"\n",
    "        reasoning_trace += f\"Observation: {observation}\\n\"\n",
    "\n",
    "    return {\n",
    "        \"trace\": reasoning_trace,\n",
    "        \"final_answer\": final_answer,\n",
    "    }\n",
    "\n",
    "demo_result = react_loop(\"What is Hyderabad?\")\n",
    "demo_result[\"trace\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722eb00",
   "metadata": {},
   "source": [
    "### 3.3 Interpreting the trace\n",
    "\n",
    "In the trace we captured:\n",
    "- `Thought:` model deciding what it needs to do\n",
    "- `Action:` which tool it chose\n",
    "- `Observation:` what came back from the tool\n",
    "- possibly `Answer:` if it can finalize now\n",
    "\n",
    "This is **auditability**:\n",
    "- Compliance can review why a tool was called\n",
    "- We can prove numbers came from calculator / DB, not hallucination\n",
    "- We can debug reasoning loops when something goes wrong\n",
    "\n",
    "This is the main reason enterprises like ReAct.\n",
    "It is not just \"chatbot\"; it is **controlled reasoning + transparent tool usage**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b101342",
   "metadata": {},
   "source": [
    "## 4. Let's test with math\n",
    "\n",
    "We'll ask the agent:\n",
    "> `123 * 7 + 10`\n",
    "\n",
    "It should:\n",
    "1. Decide to call the calculator tool\n",
    "2. Get the observation back (the math result)\n",
    "3. Produce an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ce2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_demo = react_loop(\"123 * 7 + 10\")\n",
    "print(\"=== TRACE ===\")\n",
    "print(math_demo[\"trace\"])\n",
    "print()\n",
    "print(\"=== FINAL ANSWER ===\")\n",
    "print(math_demo[\"final_answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea3d273",
   "metadata": {},
   "source": [
    "## 5. Adding your own tool (critical teaching moment)\n",
    "\n",
    "In `ReAct-Agent-from-Scratch`, there are multiple tools defined: Calculator, Wikipedia, Web Search, Weather, etc.  citeturn1view0  \n",
    "You can add *any* tool that is just a Python function.\n",
    "\n",
    "Example: `hotel_recommender` that returns a curated business hotel in Hyderabad.\n",
    "This turns the agent from \"generic Q&A\" into \"domain assistant with policy\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee76b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_hotel_recommender(city: str) -> str:\n",
    "    if city.lower() == \"hyderabad\":\n",
    "        return (\n",
    "            \"MetroLink Executive Suites (~₹5400/night). Walkable to Hitech City offices. \"\n",
    "            \"Breakfast+gym included. Good for business stays.\"\n",
    "        )\n",
    "    return \"No curated business-friendly pick for that city yet.\"\n",
    "\n",
    "TOOLS[\"hotel_recommender\"] = tool_hotel_recommender\n",
    "\n",
    "def business_policy(user_message: str, scratchpad: str) -> Tuple[str, str, str]:\n",
    "    lower_msg = user_message.lower()\n",
    "    if \"business trip\" in lower_msg and \"hyderabad\" in lower_msg:\n",
    "        return (\n",
    "            \"I should fetch a curated business hotel for Hyderabad.\",\n",
    "            \"hotel_recommender\",\n",
    "            \"Hyderabad\",\n",
    "        )\n",
    "    return simple_policy(user_message, scratchpad)\n",
    "\n",
    "def react_loop_business(user_message: str, max_steps: int = 3):\n",
    "    reasoning_trace = \"\"\n",
    "    final_answer = None\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        thought, action_name, action_input = business_policy(user_message, reasoning_trace)\n",
    "        reasoning_trace += f\"Thought: {thought}\\n\"\n",
    "\n",
    "        if action_name == \"final\":\n",
    "            final_answer = f\"Answer: {action_input}\"\n",
    "            reasoning_trace += final_answer + \"\\n\"\n",
    "            break\n",
    "\n",
    "        tool_fn = TOOLS.get(action_name)\n",
    "        if tool_fn is None:\n",
    "            observation = f\"ERROR: tool {action_name} not found\"\n",
    "        else:\n",
    "            observation = tool_fn(action_input)\n",
    "\n",
    "        reasoning_trace += f\"Action: {action_name}({action_input})\\n\"\n",
    "        reasoning_trace += f\"Observation: {observation}\\n\"\n",
    "\n",
    "        final_answer = f\"Answer: {observation}\"\n",
    "        break\n",
    "\n",
    "    return {\n",
    "        \"trace\": reasoning_trace,\n",
    "        \"final_answer\": final_answer,\n",
    "    }\n",
    "\n",
    "biz_demo = react_loop_business(\"Suggest a hotel for my business trip to Hyderabad.\")\n",
    "print(\"=== TRACE ===\")\n",
    "print(biz_demo[\"trace\"])\n",
    "print()\n",
    "print(\"=== FINAL ANSWER ===\")\n",
    "print(biz_demo[\"final_answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490afd6",
   "metadata": {},
   "source": [
    "### Why this matters\n",
    "\n",
    "Now it's not just Q&A. It's policy-aware action.\n",
    "\n",
    "- You can inject company rules (approved hotels, max nightly rate)\n",
    "- You can pull LIVE internal data (inventory, budget, compliance)\n",
    "- You still keep the transparent `Thought / Action / Observation` log to prove why the agent said what it said\n",
    "\n",
    "This is how you sell \"agentic AI\" to leadership:\n",
    "1. It can reason.\n",
    "2. It can act.\n",
    "3. It can explain itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ec705",
   "metadata": {},
   "source": [
    "## 6. How this aligns with the original repo\n",
    "\n",
    "In the repo (`agent.py`, `tools/`, `web_app.py`) you referenced citeturn1view0:\n",
    "\n",
    "- `web_app.py` (Streamlit) is the front-end chat interface.\n",
    "- `tools/` is like the `TOOLS` dict we built (calculator, wikipedia, weather, etc.).\n",
    "- `agent.py` is effectively a richer version of `react_loop`, where:\n",
    "  - The LLM (OpenAI / Gemini / etc.) generates the Thought / Action / Action Input.\n",
    "  - Python executes that tool.\n",
    "  - The Observation goes back into the LLM's context.\n",
    "  - The loop continues until the LLM decides to answer the user.\n",
    "\n",
    "This notebook is your teaching companion:\n",
    "- It explains ReAct to students and stakeholders\n",
    "- It demonstrates the reasoning trace live\n",
    "- It shows exactly where to plug in company logic (like hotel policy tools)\n",
    "\n",
    "This is how you go from \"react agent from scratch\" to \"agentic AI product for business\".\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
